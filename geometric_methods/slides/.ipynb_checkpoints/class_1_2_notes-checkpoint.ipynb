{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afbf0794",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Algorithms in Euclidean and Metric Spaces: Algorithms and Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06da9a",
   "metadata": {},
   "source": [
    "## Efficient and Balanced Trees\n",
    "\n",
    "We are looking for binary trees that allow **efficient query answers**. This relies on:\n",
    "- A tree being **balanced**\n",
    "- A tree that can perform **efficient dictionary operations**:\n",
    "    - 1) *present*, 2) *insert*, 3) *delete* (similar to CRUD operations -- Create, Read, Update, Delete -- such as found with databases such as [NoSQL](https://towardsdatascience.com/crud-create-read-update-delete-operations-on-nosql-database-mongodb-using-node-js-3979573b9b24))\n",
    "    - These operations function in *O(log n)* time (with one-dimensional data, else O(n))\n",
    "    - A tree can be built/sorted in **O(n log n) time**\n",
    "   \n",
    "An unbalanced tree has its height bounded by *n*, while a balanced tree has its height bounded by *log(n)*.\n",
    "\n",
    "![balanced](images/balanced_tree.png)\n",
    "\n",
    "<u>Note on efficient tree DS:</u> Adelson-Velsky-Landis (AVL) trees ([wiki](https://en.wikipedia.org/wiki/AVL_tree)), Red-Black Trees ([wiki](https://en.wikipedia.org/wiki/Red%E2%80%93black_tree))\n",
    "\n",
    "### Why Trees?\n",
    "\n",
    "Voronoi diagrams happen to break in higher dimensional spaces. As such, we need **more efficient data structures** to handle and process data.\n",
    "\n",
    "<u>Note on tree construction using the median:</u> Finding a median can be used to build trees. However, if it can only be efficient if the tree is static as any modification operation will break the balancedness.\n",
    "\n",
    "## Focused Solution: K-Dimensional Trees ([wiki](https://en.wikipedia.org/wiki/K-d_tree))\n",
    "\n",
    "**Definition**: k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees.\n",
    "\n",
    "**Construction**: One takes a direction (in the dimension of the data) and projects the points of the underlying dataset in that direction. Then the median is taken and the dataset split in that direction. The process is then recursed. *Points that are not bisected form the bottommest leaves* of the KD tree.\n",
    "\n",
    "**Goal**: To spread the points of a dataset the most\n",
    "\n",
    "![kdtree](images/kd_tree.png)\n",
    "\n",
    "**Relation to PCA**: PCA tries to split the points of a dataset in a way that maximizes the variance\n",
    "\n",
    "#### Driving Questions\n",
    "\n",
    "- Is it important to miss exact nearest neighbors?\n",
    "> no, especially in high dimensions\n",
    "\n",
    "- Will a failure be frequent?\n",
    "> it depends on a complexity/differentiability factor $\\phi$\n",
    "\n",
    "#### Core difficulties\n",
    "\n",
    "- <span style=\"color:red\">**Curse of dimensionality in $\\mathbb{R}^d$**</span>: For high dimensional data, it is difficult to outperform the linear scan.\n",
    "- Interpretability: the meaningfulness of distances in high dimension erodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e602e0d",
   "metadata": {},
   "source": [
    "### Search Strategies in KD-Trees\n",
    "\n",
    "#### Approximative Strategy: The defeatist approach\n",
    "\n",
    "- **Idea**: It is a simple approach that may fail, however.\n",
    "\n",
    "- **Process**: Recursively visit the subtree containing the query point\n",
    "\n",
    "- **Search cost**: O(depth + log(n/depth))\n",
    "\n",
    "- **Caveat**: Failure as the algorithm searches through one side recursively only (The failure of finding the nearest neighbor can be function of the dataset complexity $\\phi$)\n",
    "\n",
    "#### Exact Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3d2d1",
   "metadata": {},
   "source": [
    "### Pros and Cons\n",
    "\n",
    "**KD-Tree**\n",
    "> Pros: Free, fast\n",
    "> \n",
    "> Cons: Collisions\n",
    "\n",
    "**PCA**\n",
    "> Pros: Uses directions with max variances\n",
    "> \n",
    "> Cons: Computation cost\n",
    "\n",
    "RPTrees try to combine the two approaches.\n",
    "\n",
    "<u>Other trees:</u>\n",
    "- dyadic trees: split at the middle\n",
    "- k-means trees: We want to define the clusters that minimizes the intra-cluster variance (equivalent to PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9163d5",
   "metadata": {},
   "source": [
    "## Metric Trees\n",
    "\n",
    "Metric trees rely on distances over coordinates (based on metric space). The hard part of constructing metric trees is selecting points and computing the overall median.\n",
    "\n",
    "### Process\n",
    "\n",
    "We select a pivot $v$ at random and compute the median distance $\\mu$ between the pivot and all other points. The elements outside the radius $\\mu$ are recursed over to become the right subtree. The elements inside are recursed over to become the left subtree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50e078",
   "metadata": {},
   "source": [
    "## Random Projection Tree\n",
    "\n",
    "The idea goal is to separate the points in a given space for free\n",
    "\n",
    "### Process\n",
    "\n",
    "1) A random projection direction is picked\n",
    "2) The median on this projection direction is computed\n",
    "3) The median point on the projection is bisected perpendicularly to the direction and form the separation\n",
    "\n",
    "### Mathematics behind efficiency of RP-Tree\n",
    "\n",
    "$$\\exists \\text{ unique } \\alpha_{orthogonal} \\in \\text{ random direction } \\alpha \\in [0, \\pi)$$\n",
    "$$\\text{ s.t. } Vec_{\\alpha_{orthogonal}} * Vec_{best} = 0$$\n",
    "\n",
    "We call $Vec_{\\alpha_{orthogonal}}$ the worst case. Any *other* direction will have a component along $Vec_{best}$. i.e. any random vector will capture a component on $Vec_{best}$ with $\\mathbb{P}\\rightarrow 1$.\n",
    "\n",
    "> The probability of failure when choosing a direction at random goes to zero\n",
    "\n",
    "![rptree](images/rp_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78131251",
   "metadata": {},
   "source": [
    "## Notes on regression\n",
    "\n",
    "\\begin{align}\n",
    "\\text{knn regression} &: y = \\underset{i}{\\sum} \\alpha_i * x_i\\\\\n",
    "\\text{linear regression} &: y = \\frac{1}{k_n} \\underset{i}{\\sum} y_i\\\\\n",
    "\\end{align}\n",
    "\n",
    "Linear regression (using nearest neighbors) exploits locality (it is different from interpolation).\n",
    "\n",
    "#### Interpolation\n",
    "\n",
    "Interpolation has a function go through all the points of the dataset ($f(x_i) = y_i$). No approximation is performed and there is an issue of overfitting.\n",
    "\n",
    "![interp](images/interp_v_approx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881fa13",
   "metadata": {},
   "source": [
    "## Notes on intrinsic dimension\n",
    "\n",
    "The **intrinsic dimension** of a dataset corresponds to the number of independent attributes/coordinates/elements of its vecto representation (also called **degrees of freedom**).\n",
    "\n",
    "In general, the intrinsic dimension of real world datasets is small. \n",
    "\n",
    "**Note on Lattices**: Cartesian product of two vectors.\n",
    "\n",
    "**Note on Manifolds**: A d-dimension disk of points $||p-c||\\lt n$. Topological disk can be perturbed/deformed. \n",
    "\n",
    "### Local covariance dimension\n",
    "\n",
    "> **Definition**: A set $T\\subset\\mathbb{R}^D$ has *covariance dimension* $(d, \\epsilon)$ if the largest $d$ eigenvalues of its covariance matrix satisfy: $$\\sigma_1^2+...+\\sigma_d^2\\ge(1-\\epsilon)*(\\sigma_1^2+...+\\sigma_D^2)$$\n",
    "\n",
    "### Assouad Dimension (doubling dimension)\n",
    "\n",
    "> **Definition**: Fractal dimension for subsets of a metric space. How many d-dimensional cubes of side length $L/2$ are needed to cover (i.e. fit in) the original d-dimensional cube of side length $L$.\n",
    "\n",
    "The definition can be expanded to balls covering topological disks (sub-manifolds). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7d5f2",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "### Percentile Order\n",
    "\n",
    "$$PO = 100* \\frac{rank(NN(q))}{N}$$\n",
    "\n",
    "### Quality of a nearest neighbor\n",
    "\n",
    "$$NN_{quality}(q) = \\frac{d(q, NN(q))}{d(q, p_1)}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
