{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b3d235",
   "metadata": {},
   "source": [
    "# Lecture 1: Introduction & Basics\n",
    "*Notes*\n",
    "<hr>\n",
    "\n",
    "**Leading goal of the course:** teaching to build fundamentally better architectures\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c0833",
   "metadata": {},
   "source": [
    "### Key current directions\n",
    "\n",
    "Computer architecture is currently looking into producing:\n",
    "- Fundamentally **secure/reliable/safe** architectures\n",
    "- Fundamentally **energy-efficient** architectures (memory-centric arch.)\n",
    "    - <u>example:</u> data is moved around a lot within an architecture's memory, leading to inefficiency and heating as processing and memory units are separated under the Von Neumann paradigm\n",
    "- Fundamentally **low-latency and predictable** architectures\n",
    "- Specialized architectures (**AI/ML**, Genomics, Medicine, health)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fbb548",
   "metadata": {},
   "source": [
    "## 1 - The transformation hierarchy\n",
    "\n",
    "The **transformation hierarchy** is an extended view of the general understanding of computer architecture (restricted to the software/hardware interface and micro-architecture). The expanded view [of computer architecture] covers within the transformation hierarchy:\n",
    "\n",
    "*Problem*\n",
    "- **Algorithm**\n",
    "- **Program/Language**\n",
    "- **System Software**\n",
    "- **SH/HW interface**\n",
    "- **Micro-Architecture**\n",
    "- **Logic**\n",
    "- **Devices**\n",
    "\n",
    "*Electrons*\n",
    "\n",
    "The expanded view helps understand the seemless working of machines and the goal is to help **co-design** architectures by integrating the herarchy together. \n",
    "\n",
    "<u>To read:</u> \"You and your research,\" Richard Hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06a687",
   "metadata": {},
   "source": [
    "## 2 - Why study computer architecture?\n",
    "\n",
    "### Computer Architecture\n",
    "\n",
    "It is the science and art of **designing computing platforms**, including the hardware, interface, system software and programming model.\n",
    "\n",
    "It is **hard to evaluate** the whole technology stack of a machine scientifically, especially when looking forward to potential future development. It is in part art.\n",
    "\n",
    "Computer architecture aims **to achieve a set of design goals** (e.g. highest performance on a workload, longest battery life, etc.).\n",
    "\n",
    "Computer architectures/platforms can be **tailored to the task** or **generalist**.\n",
    "\n",
    "<u>i.e.</u>\n",
    "\n",
    "- Enable better systems (faster, cheaper, smaller, more reliable)\n",
    "- Enable new applications\n",
    "- Enable better solutions to problems\n",
    "- Understand why computers work the way they do\n",
    "\n",
    "\"*The goal is to optimize the top and the bottom, but also the communication between and across both top and bottom.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653f44c",
   "metadata": {},
   "source": [
    "## 3 - Some cross-layer design examples\n",
    "\n",
    "#### EDEN: Data-Aware Efficient DNN Inference\n",
    "\n",
    "- relies on approximate DRAM\n",
    "\n",
    "#### SMASH: SW/HW Indexing Acceleration\n",
    "\n",
    "- Efficient sparse matrix operations\n",
    "\n",
    "#### GenASM\n",
    "\n",
    "- low-power approximate string matching acceleration framework\n",
    "\n",
    "#### NERO\n",
    "\n",
    "- Stencil Acceleration for weather predicfion modeling\n",
    "\n",
    "#### NATSA\n",
    "\n",
    "- Near-data processing acceleration for time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85b3d7",
   "metadata": {},
   "source": [
    "## 4 - One Problem: Limited SW/HW communication\n",
    "\n",
    "Usually the higher-level information is not visible to hardware.\n",
    "\n",
    "![codesign](images/codesign.png)\n",
    "\n",
    "Solution: **more expressive interfaces**\n",
    "\n",
    "![codsol](images/codesignsol.png)\n",
    "\n",
    "Expressive Memory (e.g. X-MeM) aids on many optimization such as compression acceleration. Usually data information (metadata) is lost through the SW/HW interface.\n",
    "\n",
    "Communicating datatypes/structures is also an issue/example.\n",
    "\n",
    "Other example: memory error tolerance with hybrid memory systems can be exploited to make more reliable processes. As such being able to distinguish between vulnerable and tolerant data could help design better memory management (**Heterogeneous-Reliability Memory**, 2014).\n",
    "\n",
    "![hrm](images/HRM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c589226",
   "metadata": {},
   "source": [
    "## 5 - Ongoing Developments\n",
    "\n",
    "With regards to Moore's law, DRAM scaling is more problematic than Logic (CPU) scaling.\n",
    "\n",
    "### 1st reason why: Performance and Energy Efficiency\n",
    "\n",
    "- **non-volatile main memory** (persistent memory device, Intel Optane Persistent Memory) based on 3D-XPoint technology.\n",
    "\n",
    "- **Cerebras' Wafer Scale Engine (-2)** (largest chip on the market, specialized in ML acceleration 2.6tr transistors vs. 54.2bn in the largest GPU). \n",
    "\n",
    "- **UPMEM Processing-in-DRAM memory modules** (processor in the DRAM stick that allows computing in memory or near memory).\n",
    "\n",
    "- **Samsung Function-in-Memory DRAM**\n",
    "\n",
    "### Processing in-, near- and using memory\n",
    "\n",
    "Processing using memory relies on using the memory bank itself for computing (i.e. computing occurs as the data is accessed by using on the fundamental properties of the memory device).\n",
    "\n",
    "### Systolic Array\n",
    "\n",
    "- almost at once matrix multiplication (TPU) for ML acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae16b7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
