{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a9fdb3",
   "metadata": {},
   "source": [
    "# Stochastic Models in Neurocognition\n",
    "\n",
    "## Class 4\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Preliminary Notes**:\n",
    "\n",
    "- etienne.tanre@inria.fr (numerical homework to send), Building Cauchy C0011, +33 (0)6 66 97 44 34\n",
    "- February, final exam\n",
    "- **tutorials**:\n",
    "    - purely numeric: simulation of a process seen in class\n",
    "    - To send to teacher + Josue: josue.tchouanti-fotso@unice.fr\n",
    "        1. ***code***\n",
    "        2. ***pdf file*** including for each question/model to simulate: goal, method chosen to achieve the goal, results, comments\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f969bc",
   "metadata": {},
   "source": [
    "# 1 - Markov Chains\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Definition of Stochastic Process\n",
    "\n",
    "> We consider a probability space $\\Omega, \\mathcal{F}, \\mathbb{R})$. \n",
    ">\n",
    "> $(X_t)_{t\\in I}$ is a stochastic process if:\n",
    "\\begin{align}\n",
    "X_t:\\Omega\\times I&\\rightarrow E\\\\\n",
    "(\\omega, t)&\\rightarrow X_t(w)\n",
    "\\end{align}\n",
    ">\n",
    "> We consider:\n",
    "> - $I=\\mathbb{N}$ the **discrete time** SP ($X_t$ can be said to be a time series)\n",
    "> - $I=\\mathbb{R}_+$ the **continuous time** SP\n",
    "> - $E=\\{0,1\\}$.\n",
    "\n",
    "<u>Examples for $E$:</u> any finite sets, $E=\\mathbb{R}$ or $E=\\mathbb{R}^d$\n",
    "\n",
    "#### Vocabulary\n",
    "\n",
    "1. If $\\omega$ is fixed, $X_t(\\omega)$ is called a **path** or **trajectory**. \n",
    "2. If $t$ is fixed and is *unary* (it's not a list), $X_t(\\omega)$ is a **random variable**, and usually we are interested in its **distribution** (or law)\n",
    "\n",
    "### Definition of Markov Chains\n",
    "\n",
    "Markov Chains are a particular case of a Stochastic Process:\n",
    "\n",
    "> $I=\\mathcal{N}$; we are only interested in discrete time SP.\n",
    "> \n",
    "> A SP is a MC if and only if: $$\\forall n\\in I, \\forall p\\ge1,\\mathcal{L}(X_{n+p}|X_n,...,X_1,X_0)=\\mathcal{L}(X_{n+p}|X_n)$$\n",
    ">\n",
    "> $n$ represents the current time/present, $n+p$ represents the future.\n",
    "\n",
    "### Why are we interested in MC?\n",
    "\n",
    "The main reason is that **one can forget the past**. I.e. to be able to make a forecast, make an estimate, we only need to take a snapshot of the current state as an input parameter.\n",
    "\n",
    "<u>Example 1:</u>\n",
    "\n",
    "\\begin{align}\n",
    "I&=\\mathcal{N};\\,\\,E=\\{0,1\\}\\\\\n",
    "1&\\rightarrow\\text{, the neuron is excited};\\,\\,0\\rightarrow\\text{, the neuron is not}\\\\\n",
    "\\forall n\\in\\mathcal{N}, X_n&=\\{0,1\\}\\\\\n",
    "\\end{align}\n",
    "\n",
    "As such, the law at time $t=n+1$ is completely discribed by the probability to be in state $1$ and probability to be in state $0$.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(X_{n+1}=1|X_n=0)&=\\mathbb{P}_{0\\rightarrow1}\\\\\n",
    "\\mathbb{P}(X_{n+1}=0|X_n=0)&=\\mathbb{P}_{0\\rightarrow0}=1-\\mathbb{P}_{0\\rightarrow1}\\\\\n",
    "\\mathbb{P}(X_{n+1}=1|X_n=1)&=\\mathbb{P}_{1\\rightarrow1}=1-\\mathbb{P}_{1\\rightarrow0}\\\\\n",
    "\\mathbb{P}(X_{n+1}=0|X_n=1)&=\\mathbb{P}_{1\\rightarrow0}\\\\\n",
    "\\text{with}&,\\\\\n",
    "\\mathbb{P}_{0\\rightarrow0} + \\mathbb{P}_{0\\rightarrow1} &= 1\\\\\n",
    "\\mathbb{P}_{1\\rightarrow0} + \\mathbb{P}_{1\\rightarrow1} &= 1\n",
    "\\end{align}\n",
    "\n",
    "We can represent this as a matrix:\n",
    "\n",
    "$$\\begin{pmatrix} \\mathbb{P}_{0\\rightarrow0} & \\mathbb{P}_{0\\rightarrow1} \\\\ \\mathbb{P}_{1\\rightarrow0} & \\mathbb{P}_{1\\rightarrow1} \\end{pmatrix}$$\n",
    "\n",
    "<u>Example 2:</u>\n",
    "\n",
    "\\begin{align}\n",
    "X_{n+1}=1&\\text{ with probability }q_{i,j\\rightarrow1}\\\\\n",
    "X_{n+1}=0&\\text{ with probability }q_{i,j\\rightarrow0} = 1-q_{i,j\\rightarrow1}\\\\\n",
    "\\text{if }X_n=i&;\\,\\,X_{n-1}=j\n",
    "\\end{align}\n",
    "\n",
    "If $q_{i,j\\rightarrow1}\\neq q_{i,1-j\\rightarrow1}$, $X_n$ is not a MC.\n",
    "\n",
    "<span style=\"color:red\">In this case $q_{1,1\\rightarrow1}\\neq q_{1,0\\rightarrow0}$, It means that $\\mathbb{P}(X_{n}=1|X_n-1, X_{n-1}=1)=q_{1,1\\rightarrow1})$ is not equal to $\\mathbb{P}(X_{n}=1|X_n-1, X_{n-1}=1)=q_{1,0\\rightarrow1})$</span>\n",
    "\n",
    "In this case, we introduce a *new* SP. We consider:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{X}_n = (X_n, X_{n-1})\\\\\n",
    "E=\\{(0,0), (0,1), (1,0), (1,1)\\}\n",
    "\\end{align}\n",
    "\n",
    "**Property**: $\\hat{X}_n$ is a MC if\n",
    "\n",
    "<span style=\"color:red\">ADD PROB with MATRIX VALUES HERE</span>\n",
    "\n",
    "<u>In general:</u>\n",
    "\n",
    "> If one wants to consider a SP s.t. the law of the position of at time $n+1$ depends on a finite past, say $X_n, X_{n-1},...,X_{n-d}$, we introduce: $\\tilde{X}_n=(X_n, X_{n-1},...,X_{n-d})$ with $\\tilde{E}=\\{0,1\\}^{d+1}$ and $\\tilde{X}_n$ is a MC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06614644",
   "metadata": {},
   "source": [
    "## How to simulate a MC (<span style=\"color:red\">HOMEWORK</span>)\n",
    "\n",
    "We introduce 2 sequences of Bernouilli  random variables with parameters:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}_{0\\rightarrow1}\\\\\n",
    "\\mathbb{P}_{1\\rightarrow0}\\\\\n",
    "(Y_i)_{i\\in \\mathcal{N}}&,\\mathbb{P}(success =Y_i)=\\mathbb{P}_{0\\rightarrow1}\\\\\n",
    "(Z_i)_{i\\in \\mathcal{N}}&,\\mathbb{P}(success =Z_i)=\\mathbb{P}_{1\\rightarrow0}\\\\\n",
    "Z_i, Y_i&\\in\\{0, 1\\}\\\\\n",
    "X_{n+1} &= X_n*(1-Z_{n+1}) + (1-X_n)*Y_{n+1}\\\\\n",
    "X_{n+1} &= X_n*\\mathbb{1}_{[\\mathbb{P}_{1\\rightarrow0}, 1]}(U_{n+1}) + (1-X_n)*\\mathbb{1}_{[0, \\mathbb{P}_{0\\rightarrow1}]}(U_{n+1}\n",
    "\\end{align}\n",
    "\n",
    "Where $(U_n)_{n\\ge1}$ is a sequence of IID random variables with the uniform distribution on [0,1]\n",
    "\n",
    "We assume that the two processes are independent and that $Y_1, ..., Y_n$ and $Z_1, ..., Z_n$ are IID respectively (they don't share the same law).\n",
    "\n",
    "#### Homework remarks\n",
    "\n",
    "- Choose an **initial condition**, i.e. the value of $X_0$\n",
    "- choose the **parameters** $\\mathbb{P}_{0\\rightarrow1}\\in[0,1]$ and $\\mathbb{P}_{1\\rightarrow0}\\in[0,1]$\n",
    "- Simulate many MC!\n",
    "- Possible different implementations: Simulate a bernouilli (bernouilli function or uniform discrete on 0, 1), i.e. $\\mathcal{B}(p)\\sim U[0,1]$, $Y=\\mathbb{1}_{[0,p]}(U)$\n",
    "    1. simulated the full sequence X_n\n",
    "    2. simulate the sequence with the uniform\n",
    "    3. simulate using a pruning algorithm\n",
    "    4. TIME THEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cabad5",
   "metadata": {},
   "source": [
    "# 2 - Continuous time Markov Processes\n",
    "\n",
    "It means that $I=\\mathbb{R}_+$\n",
    "\n",
    "## Definition\n",
    "\n",
    "$$\\forall t\\ge 0, s>0, \\mathcal{L}(X_{t+s}|(X_u)_{0\\le u \\le t}) = \\mathcal{L}(X_{t+s}|X_t)$$\n",
    "\n",
    "<u>Example 1 (simple):</u>\n",
    "\n",
    "$E=\\{0,1\\}$, the MP is completely described by two rates $\\alpha$ (the rate of jump between state $0$ to state $1$) and $\\beta$ (the rate of jump between state $1$ to state $0$). \n",
    "\n",
    "**definition of rate**: \n",
    "\n",
    "> For physicists, the rate is: $\\mathbb{P}(X_{t+\\delta}=1|X_{t}=0)\\approx\\alpha*\\delta$\n",
    ">\n",
    "> $\\underset{\\delta\\rightarrow0}{lim}\\,\\, \\frac{1}{\\delta}\\mathbb{P}(X_{t+\\delta}=1|X_{t}=0)=\\alpha$\n",
    "\n",
    "<span style=\"color:red\">ADD GRAPH</span>\n",
    "\n",
    "## Link with MC\n",
    "\n",
    "<span style=\"color:red\">ADD GRAPH</span>\n",
    "\n",
    "I introduce a \"small\" parameter $\\delta$ (delta means an accuracy of a measure that specify the maximum 'frequency'/'rate' of an underlying process) and the discrete time process $\\tilde{X}_n = X_n\\delta$.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(\\tilde{X}_{n+1}=1|\\tilde{X}_n=0)\\approx \\alpha\\delta\\\\\n",
    "\\mathbb{P}(\\tilde{X}_{n+1}=0|\\tilde{X}_n=1)\\approx \\beta\\delta\\\\\n",
    "\\end{align}\n",
    "\n",
    "We can approximate the continuous time MP with a MC ($Y_n$) with parameters $\\mathbb{P}_{0\\rightarrow1}=\\alpha\\delta$ and $\\mathbb{P}_{1\\rightarrow0}=\\beta\\delta$\n",
    "\n",
    "If we set $Z_t = Y_{\\frac{t}{\\delta}}$, $X_t$ has a law close to the law of $X_t$: $\\mathcal{L}(Z_t)\\approx\\mathcal{L}(X_t)$.\n",
    "\n",
    "## MC/MP relation\n",
    "\n",
    "These 2 processes $Y_n$ and $X_t$ take only two values: 0 and 1. As such, they are **fully-characterized by the time at which they jump**. \n",
    "\n",
    "<span style=\"color:red\">ADD GRAPH</span>\n",
    "\n",
    "The knowledge of $(\\tau_1, ...,\\tau_k,...)$ is equivalent to the knowledge of the complete trajectory.\n",
    "\n",
    "Consider the sequence (with $\\alpha\\delta<1$):\n",
    "\\begin{align}\n",
    "\\tilde{\\tau}_1&=\\delta x \\text{, the first jumping time of the markov chain $(Y_n)$}\\\\\n",
    "\\tilde{\\tau}_2&=\\delta x\\text{, the second...}\\\\\n",
    "t&=p\\delta;\\,\\,Y_0=0\\\\\n",
    "\\mathbb{P}(\\tilde{\\tau}_1\\ge t)&=(1-\\alpha\\delta)^p = (1-\\frac{\\alpha t}{p})^p\\underset{p\\rightarrow\\infty}{\\rightarrow} exp(-\\alpha t)\n",
    "\\end{align}\n",
    "\n",
    "<span style=\"color:red\">ADD GRAPH</span>\n",
    "\n",
    "\\begin{align}\n",
    "t&=p\\delta\\text{ (p going to infinity is equivalent to letting t go to 0)}\\\\\n",
    "(1-\\frac{\\alpha t}{p})^p&=exp(p*\\log(1-\\frac{\\alpha t}{p})) \\approx exp(p(-\\frac{\\alpha t}{p}+\\omicron(\\frac{1}{p^2}))=exp(-\\alpha t)\\\\\n",
    "ADD TWO MISSING FORMULAS\n",
    "\\end{align}\n",
    "\n",
    "> **We recognize the distribution of $\\tau_1\\rightarrow\\mathcal{E}(\\lambda)$ exponential law with parameter $\\lambda=\\alpha$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978fcde",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Reminder on Exponential laws\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{E}(\\lambda)\\sim f(\\theta)&=0\\text{ if $\\theta<0$}\\\\\n",
    "&=\\lambda exp(-\\lambda\\theta)\\text{ if $theta\\ge0$}\n",
    "\\end{align}\n",
    "\n",
    "<span style=\"color:red\">ADD CDF</span>\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{E}[Z] = \\int^{+\\infty}_0\\lambda\\theta exp(-\\lambda\\theta)d\\theta=\\frac{1}{\\lambda}\\\\\n",
    "Var(Z) = \\frac{1}{\\lambda^2}\n",
    "\\end{align}\n",
    "\n",
    "An exponential distribution has no memory implies that:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(Z\\ge t+s|Z\\ge t) = \\mathbb{P}(Z\\ge s)\n",
    "\\end{align}\n",
    "\n",
    "<hr>\n",
    "\n",
    "Thanks to this simple computation, one can directly **simulate the jumping time of the continuous time MP**.\n",
    "\n",
    "\\begin{align}\n",
    "\\tau_1&\\overset{\\mathcal{L}}{=}\\mathcal{E}(\\alpha)\\\\\n",
    "\\tau_2-\\tau_1&\\overset{\\mathcal{L}}{=}\\mathcal{E}(\\beta)\\\\\n",
    "\\tau_3-\\tau_2&\\overset{\\mathcal{L}}{=}\\mathcal{E}(\\alpha)\\\\\n",
    "\\end{align}\n",
    "\n",
    "## How to simulate a MP (<span style=\"color:red\">HOMEWORK</span>)\n",
    "\n",
    "Simulate $(Y_n)$ with parameters $\\alpha\\delta$ and $\\beta\\delta$. Evaluate the distribution of $\\tau_1^\\delta=N_1\\delta$ where $N_1$ is the first time $Y_1 = 1$ (apply the previous algorithm but by modifying the parameters)\n",
    "\n",
    "Plot the empirical distribution of $\\tau_1^\\delta$ for small $\\delta$ and compare with the distribution of $\\mathcal{E}$ with parameter $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b399d1d",
   "metadata": {},
   "source": [
    "# 3 - Next Week: Generalization\n",
    "\n",
    "Generalization to $E=\\{1,2,...,d\\}$ where a graph of jumps is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e91a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
