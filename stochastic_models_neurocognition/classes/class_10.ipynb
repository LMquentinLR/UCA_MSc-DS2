{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc665ff",
   "metadata": {},
   "source": [
    "# Stochastic Models in Neurocognition\n",
    "\n",
    "## Class 10\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Preliminary Notes**:\n",
    "\n",
    "Class will introduce the concept of white noise, brownian motion, some models of individual neurons known as integrate and fire models, and Large Networks of Neurons in Interaction Mean Fields Models.\n",
    "\n",
    "**Homework**:\n",
    "\n",
    "Both algorithm Brownian Motion (Donsker + normal)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffa723",
   "metadata": {},
   "source": [
    "# 1 - White Noise & Brownian Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66595925",
   "metadata": {},
   "source": [
    "## White Noise\n",
    "\n",
    "### Toy example\n",
    "\n",
    "Consider the simples random walk defined as:\n",
    "\n",
    "> Let $(X_i)$ a sequence of IID random variables s.t. $P(X_1=1) = P(X=-1)=\\frac{1}{2}$\n",
    ">\n",
    "> We defined the random walk $S_n=\\underset{i}{\\overset{n}{\\sum}} X_i$\n",
    ">\n",
    "> **Rmk:** \n",
    ">\n",
    "> $\\frac{S_n}{n} = \\frac{1}{n}\\underset{i}{\\overset{n}{\\sum}} X_i\\overset{a.s.}{\\underset{n\\rightarrow\\infty}{\\rightarrow}}\\mathbb{E}[X]=0$ (Strong Law of Large Numbers)\n",
    "> \n",
    "> **Central Limit Theorem**: Assume $(Y_n)$ is a sequence of IID R.V. with finite variance $\\mathbb{E}[Y^2]$ is finite then we know that, given $m = E[Y], \\sigma^2=Var[Y]$, then $\\frac{\\sqrt{n}}{\\sigma}(1/n \\underset{i}{\\overset{n}{\\sum}} Y_i - n)$ converges as n goes to infinity in law to a standard gaussian distribution $N(0,1)$. \n",
    "\n",
    "<img src=\"images/BM1.png\">\n",
    "\n",
    "<img src=\"images/BM2.png\">\n",
    "\n",
    "A question is **what is the asymptotic behavior of the random walk as $n\\rightarrow\\infty$**.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{S_n}{n} &= \\frac{1}{n}\\underset{i}{\\overset{n}{\\sum}}\\\\\n",
    "\\frac{\\sqrt{n}}{1}(\\frac{1}{n} S_n - 0) &\\overset{law}{\\underset{n\\rightarrow\\infty}{\\rightarrow}}\\mathcal{N}(0, 1)\\\\\n",
    "\\frac{1}{\\sqrt{n}} S_n &\\overset{law}{\\underset{n\\rightarrow\\infty}{\\rightarrow}}\\mathcal{N}(0, 1)\\\\\n",
    "\\end{align}\n",
    "\n",
    "This result is known as ***Donsker's Theorem*** such that:\n",
    "\n",
    "\\begin{align}\n",
    "W^{(n)}_t&=\\frac{1}{\\sqrt{n}} S_{\\lfloor nt \\rfloor}\\\\\n",
    "(W_t^n)_{t\\in[0,\\infty]} &\\overset{law}{\\underset{n\\rightarrow\\infty}{\\rightarrow}} (W_t)_{t\\ge0}\\text{ (Where $(W_t)$ brownian motion stochastic process)}\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/BM3.png\">\n",
    "\n",
    "Donsker's Theorem is more general if one consider a sequence $(Z_i)$ of IID random variables with mean $0$ and variance $\\sigma$. The same results hold.\n",
    "\n",
    "\\begin{align}\n",
    "(\\frac{1}{\\sqrt{n}}\\overset{\\lfloor nt \\rfloor}{\\underset{i=1}{\\sum}} Z_i)_{t\\in[0,T]} \\rightarrow (\\sigma W_t)_{t\\in[0,T]}\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/BM4.png\">\n",
    "<img src=\"images/BM5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa8a1a",
   "metadata": {},
   "source": [
    "## Definition of a Brownian Motion\n",
    "\n",
    "We say that a stochastic process $(W_t)_{t\\ge0}$ is a standard Brownian Motion if:\n",
    "\n",
    "- $W_0=0$\n",
    "- $t\\rightarrow W_t$ are continuous\n",
    "- The increments are independent: $\\forall 0\\le s\\le t, W_t-W_s$ is independent of $W_s$\n",
    "    - same with $t_1\\le t_2\\le\\ldots\\le t_k,(W_{t_i+x} -W_{t+i})_{x\\in[1, k]}$ are independent\n",
    "- The law of $W_t-W_s$ is $\\mathcal{N}(0, t-s)$. \n",
    "\n",
    "### Simulation of a BM trajectory  (synonymous with Weiner Process)\n",
    "\n",
    "1. Introduce a time length and a time step $\\forall i \\in [0, n], t_i$, e.g. $t_i = i\\eta$ for a fixed $\\eta$ a discretization step\n",
    "2. At time $t_1$, the position $W_{t_1}  \\overset{law}{=} \\mathcal{N}(0, t_1) \\overset{law}{=} \\sqrt{t_1}\\mathcal{N}(0, 1)$\n",
    "2. The position $W_{t_2} = W_{t_2} -  W_{t_1} +  W_{t_1}$:\n",
    "    - we add to the previous position a Gaussian RV s.t. $W_{t_2} -  W_{t_1}\\overset{law}{=} \\mathcal{N(0, t_2 - t_1)} = \\sqrt{t_2 - t_1}\\mathcal{N(0, 1)}$\n",
    "    \n",
    "<img src=\"images/BM7.png\">\n",
    "    \n",
    "### Use of the Donsker's Theorem as an alternative\n",
    "\n",
    "1. Choose a large $n$.\n",
    "2. Set $W_t = \\frac{1}{\\sqrt{n}}\\overset{\\lfloor nt\\rfloor}{\\underset{k=1}{\\sum}}X_k$ with $P(X_k=1)=P(X_k=-1)=\\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68e708",
   "metadata": {},
   "source": [
    "### How do we improve dynamic systems with noise?\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{dV_t}{dt} &= b(V_t) + \\sigma\\zeta_t\\text{ (with zeta the white noise)}\\\\\n",
    "dV_t &= b(V_t)dt + \\zeta_tdt\\\\\n",
    "& = b(V_t)dt + \\sigma dW_t\\\\\n",
    "\\zeta_t&\\sim\\text{ (white noise)}\n",
    "\\end{align}\n",
    "\n",
    "**Formally for physicist, the white noise is defined as $\\frac{dW_t}{dt}$.** In practice it means:\n",
    "\n",
    "\\begin{align}\n",
    "V_t &= V_0 + \\int_0^tb(V_s)ds + \\sigma W_t\\text{ (Noise is additive)}\\\\\n",
    "\\sigma&,\\text{ (the intensity of the additive noise)}\n",
    "\\end{align}\n",
    "\n",
    "The above equation is an equation with additive noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f93bd",
   "metadata": {},
   "source": [
    "# 2 - Deterministic Integrate and Fire Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df657633",
   "metadata": {},
   "source": [
    "### Conceptualization\n",
    "\n",
    "We need to deduce from the data a dynamical system in the case of neurocognition. \n",
    "\n",
    "- The dynamics between the spikes of the membrane potential is given as a solution of the dynamical system (ordinary differential equation):\n",
    "\n",
    "$$\\frac{dV_t}{dt}=b(V_t)$$\n",
    "\n",
    "- We consider a threshold $S$:\n",
    "    - At time where $V_t$ crosses the constant level $S$, there is a spike\n",
    "    - After a \"small\" delay $\\delta$, $V_{\\tau_1+\\delta}=V^r$\n",
    "    \n",
    "<img src=\"images/BM6.png\">\n",
    "\n",
    "A usual $b$ function is:\n",
    "\n",
    "\\begin{align}\n",
    "b(V_t) &= \\frac{1}{\\tau}(\\tau-v)\\text{   (Leaky Integrate and Fire Model)}\\\\\n",
    "b(V_t) &= \\frac{1}{\\tau}\\text{   (Perfect Integrate and Fire Model)}\n",
    "\\end{align}\n",
    "\n",
    "Those models are deterministic s.t. $\\tau_2-\\tau_1 = tau_{i+1}-\\tau_i$.\n",
    "\n",
    "### Extension: Noisy Integrate and Fire Models\n",
    "\n",
    "The neurons spike at time where $(V_t)$ crosses the threshold $S$.\n",
    "\n",
    "\\begin{align}\n",
    "dV_t &= b(V_t)dt + \\epsilon dW_t\\text{   (dynamic between spikes)}\\\\\n",
    "V_{\\tau_1+\\delta} &= V^r\n",
    "\\end{align}\n",
    "    \n",
    "<img src=\"images/BM8.png\">\n",
    "\n",
    "For this model, the noisy IF model, **the interspike intervals are random**.\n",
    "\n",
    "### Algorithm(s) to generate the Noisy Integrate and Fire Model\n",
    "\n",
    "One can generate raster plots for neurons evolving according to the NIF model.\n",
    "\n",
    "1. Fix a time step/discretization $\\eta$\n",
    "2. At each time step $t_k = k\\eta$\n",
    "    - 2.a $\\tilde{V}_{t_{k+1}} = \\bar{V}_{t_k} + b(\\bar{V}_{t_k})\\eta + \\epsilon.(W_{t_{k+1}} - W_{t_k})$ with $\\epsilon$ an intensity parameter and $(W_{t_{k+1}} - W_{t_k}) \\sim \\sqrt{\\eta}\\mathcal{N}(0,1)$\n",
    "    - 2.c If $\\tilde{V}_{t_{k+1}}\\le S$, we set $\\tilde{V}_{t_{k+1}} = \\bar{V}_{t_{k+1}}$\n",
    "    - 2.b If $\\tilde{V}_{t_{k+1}}>S$, we decide that the neuron spikes on $[t_k, t_{k+1}]$ and we set $\\tau^t = t_k$\n",
    "    \n",
    "<img src=\"images/BM9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e567c",
   "metadata": {},
   "source": [
    "### Estimation of $b$ and $\\epsilon$\n",
    "\n",
    "<u>**Estimation of $b$**:</u>\n",
    "\n",
    "Imagine one observes the trajectoy of the system without noise, that is $\\epsilon=0$ s.t. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{dV_t}{dt}&=b(V_t)\\\\\n",
    "V_t &= V_s + \\int_s^t\\frac{dV_\\theta}{dt}d\\theta\\\\\n",
    "&= V_s + \\int_s^tb(V_\\theta)d\\theta\n",
    "\\end{align}\n",
    "\n",
    "Take a time step $t^*$ such that $V_t\\approx v$ and $b(v) = \\frac{V_{t^*+\\eta} - V_{t^*-\\eta}}{2\\eta}\\mathbb{1}_{V_{t^*}=v}$\n",
    "\n",
    "<img src=\"images/BM11.png\">\n",
    "<img src=\"images/BM10.png\">\n",
    "\n",
    "<u>**Estimation of $\\epsilon$**:</u>\n",
    "\n",
    "**Properties**:\n",
    "- The length of a trajectory of Brownian Motion is infinite\n",
    "- $(W_t)_{0\\le t\\le1}$, consider a partition of $(0, 1)$ that is $0<t_0<t_1<...<t_k=1$\n",
    "- $\\underset{j=1}{\\overset{k-1}{\\sum}}|W_{t_{j+1}}-W_{t_j}|\\underset{\\eta\\rightarrow0}{\\rightarrow}\\infty$\n",
    "- the BM has finite quadratic variation s.t. \n",
    "\n",
    "\\begin{align}\n",
    "\\eta,T_k&=k\\eta\\\\\n",
    "\\underset{j=1}{\\overset{\\lfloor t/\\eta \\rfloor}{\\sum}}(W_{t_{j+1}}-W_{t_j})^2&\\underset{\\eta\\rightarrow0}{\\rightarrow}T\\\\\n",
    "\\eta &=\\frac{T}{N}\\\\\n",
    "\\underset{j=0}{\\overset{N-1}{\\sum}}[\\sqrt{t_{j+1}-t_j}G_{j+1}]^2&,\\text{ where $G\\sim\\mathcal{N}(0,1)$ IID}\\\\\n",
    "&= \\underset{j=0}{\\overset{N-1}{\\sum}}\\frac{T}{N}G_{j+1}^2 = \\frac{T}{N}\\underset{j=0}{\\overset{N-1}{\\sum}}G_{j+1}^2\\\\\n",
    "&= \\frac{T}{N}\\underset{j=1}{\\overset{N}{\\sum}}G_j^2\\\\\n",
    "\\frac{1}{N}\\underset{j=1}{\\overset{N}{\\sum}}G_j^2\\overset{as}{\\underset{N\\rightarrow\\infty}{\\rightarrow}}\\mathbb{E}[G_1^2]=1\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/BM12.png\">\n",
    "\n",
    "**Generalization**:\n",
    "\n",
    "Assume $(X_t)_{t\\ge0}$ is solution of the Stochastic Differential Equation:\n",
    "\n",
    "$$dX_t = g(X_t)dt + \\epsilon dW_t$$\n",
    "\n",
    "Then,\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{j=0}{\\overset{\\lfloor T/\\eta \\rfloor}{\\sum}}(X_{t_{j+1}}-X_{t_j})^2\\underset{\\eta\\rightarrow0}{\\rightarrow}\\epsilon^2T\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/BM13.png\">\n",
    "\n",
    "$$\\underset{\\eta\\rightarrow0}{lim} \\frac{V_{t^*+\\eta} - V_{t^*-\\eta}}{2\\eta}\\mathbb{1}_{V_{t^*}=v} = \\underset{\\eta\\rightarrow0}{lim} \\hat{b}^\\eta(v) = b(v)$$\n",
    "\n",
    "<img src=\"images/BM14.png\">\n",
    "\n",
    "<u>**Issue with estimating $\\epsilon$**:</u>\n",
    "\n",
    "> The estimator used for $\\epsilon = 0$ does not work.\n",
    "\n",
    "Instead. Fix a value $v$ and observe on the trajectory times $t^*_1, \\dots t^*_l$ where:\n",
    "\n",
    "\\begin{align}\n",
    "V_{t^*_i}&\\approx v\\\\\n",
    "\\hat{b}^\\eta(v)&=\\frac{1}{l}\\underset{i=1}{\\overset{l}{\\sum}}\\frac{V_{t^*+\\eta} - V_{t^*-\\eta}}{2\\eta}\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/BM15.png\">\n",
    "\n",
    "<img src=\"images/BM16.png\">\n",
    "\n",
    "# 3 - Large Networks of Neurons in Interaction Mean Fields Models\n",
    "\n",
    "## General outlook\n",
    "\n",
    "- Consider one has a good model of individual neurons. \n",
    "- One can observe the spikes.\n",
    "- One can observe the membrane potential of neuron 1.\n",
    "    - At the spiking time, the membrane potential of the neuron 1 is reset to $V^r$ (with a delay $\\delta$)\n",
    "    - The membrane potentials of the other neurons also receive a jump $J^{1\\rightarrow i}$\n",
    "\n",
    "$J^{i\\rightarrow j}$ (the **synaptic weight**) represents the effects of a spike emitted by neuron $i$ on the membrane potential of neuron $j$ -- creating a jump. There are three cases:\n",
    "\n",
    "- $J^{i\\rightarrow j}$ is positive: excitatory connection\n",
    "- $J^{i\\rightarrow j}$ is negative: inhibitory connection\n",
    "- $J^{i\\rightarrow j}$ is null: independent, non-connectedness (oriented property)\n",
    "\n",
    "The property to be excitatory or inhibitory is a property of the neuron, $(J^{1\\rightarrow j}>0) \\cup (J^{1\\rightarrow k}<0)$ is not possible.\n",
    "\n",
    "<img src=\"images/BM17.png\">\n",
    "<img src=\"images/BM18.png\">\n",
    "\n",
    "We need to beware the **cascade phenomenon** where the a spiking neuron can spike another one. \n",
    "\n",
    "## What about large neurons\n",
    "\n",
    "$$V_t^i = V_0^i + \\int^t_0b(V_\\theta^i)d\\theta + \\epsilon W_t^i + (V^r-S)M_t^i+\\underset{j=1, j\\neq i}{\\overset{n}{\\sum}}J^{j\\rightarrow i}M^j_t$$ Where $M^j_t$ is the number of jumps of neuron $j$ on $[0, t]$ (a counter). \n",
    "\n",
    "With such networks, we consider that the additive noises are due to \"internal\" small modifications. But the **noises/W** are independent.\n",
    "\n",
    "\\begin{align}\n",
    "V_t^i&=V_0^i+\\int_0^tb(V_\\theta^i)d\\theta + \\epsilon W_t^i + (V^r-S)M_t^i + \\underset{j\\neq i}{\\sum}J^{j\\rightarrow i}M_t^j\\\\\n",
    "\\frac{\\alpha}{N}\\underset{j\\neq i}{\\sum}J^{j\\rightarrow i}M_t^j&\\approx \\alpha\\mathbb{E}[M_t^1]\\\\\n",
    "\\end{align}\n",
    "\n",
    "<u>Simplest case:</u> \n",
    "- network of all to all connected nerons\n",
    "- $J^{j\\rightarrow i} = \\alpha^{(N)}=\\alpha/N$ doesn't depend on the pair of neurons\n",
    "\n",
    "$$V_t^i=V_0^i+\\int_0^tb(V_\\theta^i)d\\theta + \\epsilon W_t^i + (V^r-S)M_t^i + \\alpha\\mathbb{E}[M_t^1]$$\n",
    "\n",
    "<img src=\"images/BM19.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b83ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
