{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practicum_3_deepgenerativemodels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jarvIzm6TMq_"
      },
      "source": [
        "# MSc Data Science: (deep) discriminative models for **MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3sguCcpg2Yw"
      },
      "source": [
        "# Loading useful stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMPYV_R2ghyx"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfd = tfp.distributions"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zTFbzrTaie"
      },
      "source": [
        "#Loading and normalising MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo-tSpBxTMVq"
      },
      "source": [
        "(train_images, y_train), (test_images,  y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28*28)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28*28)\n",
        "\n",
        "y_train = tf.cast(y_train, tf.int32)\n",
        "y_test =tf.cast(y_test, tf.int32)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "dokv8mqDTMYD",
        "outputId": "de9c26ce-cf28-402f-c90e-9c65b7a47d89"
      },
      "source": [
        "plt.imshow(train_images[0, :].reshape((28,28)), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oshsOP18ToYt"
      },
      "source": [
        "# Normalizing the images to the range of [0., 1.]\n",
        "train_images = train_images/255.\n",
        "test_images = test_images/255."
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "y6xHfUaMbz6T",
        "outputId": "4af61aa4-0f76-49e4-a1fb-ad1360833cfa"
      },
      "source": [
        "import pandas as pd\n",
        "print(np.max(train_images[0,:]))\n",
        "mean_0 = np.mean(train_images[y_train == 0], axis=0)/np.max(mean_0)\n",
        "print(np.max(mean_0))\n",
        "plt.imshow(mean_0.reshape((28,28)), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.7906022716363347\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJOklEQVR4nO3d2U5VWxSE4blpFAGlEUQaRTA0ivr+z6ECEkRRQAQEFWmlO7fnglVl2OHswvN/l44sJBvLlVAZc9YuLi4KgDxNjf4GAFyOcAKhCCcQinACoQgnEKpFDWu1Gr/KBa7ZxcVF7bI/580JhCKcQCjCCYQinEAowgmEIpxAKMIJhCKcQCjCCYQinEAowgmEIpxAKMIJhCKcQCjCCYQinEAowgmEIpxAKMIJhCKcQCjCCYQinEAoeTQmrketdulJiHb2X8wVd+lVvZdiqeev++9OxJsTCEU4gVCEEwhFOIFQhBMIRTiBUIQTCEXPeQnXBTY3N8t5a2urnLe1tVXOurq65LO9vb1y7p5385aW6n8Sx8fH8tnd3V05397elvPv379f+WsfHR3J+enpqZwn9qS8OYFQhBMIRTiBUIQTCEU4gVCEEwhFOIFQ/8ues6lJ/5+kur5SSrlz546cuy5xcHCwcjY2NiafnZyclHP3/MDAgJyrDnZvb08+u7q6KueLi4tyPj8/XzlbXl6Wz25sbMj5r1+/5Nz1oI3AmxMIRTiBUIQTCEU4gVCEEwhFOIFQhBMI9df2nKrLrLfH7Ovrk/PHjx/L+fT0dOXsxYsXV372T/7u+/fvy7naRXVd4ObmppwPDw/LueqHb9++LZ89Pz+X85OTEznf39+X80bse/LmBEIRTiAU4QRCEU4gFOEEQhFOINSNrVLc8ZWqSnG/lu/p6ZFzV1fMzMzI+atXrypnU1NT8llXR9y7d0/O3eemKglXQT148EDOXR1xdnZWOXNHX7oqxK271Xu05nXgzQmEIpxAKMIJhCKcQCjCCYQinEAowgmE+mt7TrX6dPfuXfns0NCQnE9MTMj58+fPr/x8vV2hOyLS9YFqtcpdbeg6Vtcvq/74x48f8tmtrS05X19fl3N1/WAp9JwA/oVwAqEIJxCKcAKhCCcQinACoQgnEOrG9pzuGj91lV1/f798dnR0VM7dzuXTp0/lXB1PWe/xk+4avnquynM9pds1dZ9LZ2dn5cx1z27H9v3793K+srIi54eHh3J+HXhzAqEIJxCKcAKhCCcQinACoQgnEIpwAqFubM/pdgvVdXKuM3N93Pj4uJy7HlVxe4cLCwty7vq8z58/y7na93RXI7rPxVH9sdsVHRwclHN3baPrcBuBNycQinACoQgnEIpwAqEIJxCKcAKhCCcQKrbndOfSul5K7Uy63T/X17lOzXWwaqdydnZWPvv69Ws5X1paknO3D/r79+/Kmdq3LMX/zNznpvZBXc+peu1S/J2rav+3UXhzAqEIJxCKcAKhCCcQinACoQgnECq2SnFHX7pf66tf24+NjclnR0ZG5Lyjo0PO9/b25FytdbmqxFUtX758kfODgwM5V1cMumM7f/78Kefumj21ruZ+3q6+am9vl/Nbt27JeSPw5gRCEU4gFOEEQhFOIBThBEIRTiAU4QRCxfaczc3Nct7d3S3nav3IrYypdbNSSjk/P5dzdw3f3Nxc5Wx+fl4+666qU1f4leK7StUvu7Wqs7Ozuubqe3OfuepnS/G9eUuLjoJah3N/91Xx5gRCEU4gFOEEQhFOIBThBEIRTiAU4QRCxfacrndyXaTqOR8+fCifdbt/W1tbcv7x40c5X1xcrJy5fUzXY6qjLUvxnZzq81z37I4rdVcIqp+560iPj4/rml9XV1kP3pxAKMIJhCKcQCjCCYQinEAowgmEIpxAqNie03VmfX19cq66THddnNsdrLfnXFtbq5zt7u7KZ12P6fpAt9eozn911/C5n0lvb6+cq31R11O6/tedJew+10bgzQmEIpxAKMIJhCKcQCjCCYQinEAowgmEiu053X2JPT09cq7OtXXnr7pOzfWcX79+lXPVZZ6cnMhnXQfrekzXH6vPbWhoSD47Ojoq5+rO1FL0z9zd/bm5uSnnOzs7cn50dCTnjcCbEwhFOIFQhBMIRTiBUIQTCEU4gVCxVYr7lb87vlLVJa5ucFXK/v6+nB8eHsq5WutSR1OWole6SvEVlLs6UdUhz549k89OTk7KuVspUzWRq6/ckaIbGxty7n5mjTg6kzcnEIpwAqEIJxCKcAKhCCcQinACoQgnECq253RdpOud6uml3FV3rkvs7OyUc3XEpPu+3efijq989OiRnE9PT1fOXr58KZ998uSJnLtVvfX19crZp0+f5LMrKyty/u3bNzl33XYj8OYEQhFOIBThBEIRTiAU4QRCEU4gFOEEQsX2nO4IyIODAzlX+3nua7ue0nWFU1NTcq52Nt1Vda5jHRgYkHPXRU5MTFTOhoeH5bPue3M7lUtLS1ealeJ7Tne0pjuStBF4cwKhCCcQinACoQgnEIpwAqEIJxCKcAKhYnvOeq/hU1fCuS7RXXU3MzMj526nUvWg9facvb29cu560Hp2Td3ZsQsLC3I+NzdXOVtcXJTPumsX3VnDrvtuBN6cQCjCCYQinEAowgmEIpxAKMIJhIqtUtxK2NrampyrX70PDg7KZ10d4Van3EqZWmer5/rAUvyxnq4O2dnZqZy54ylnZ2fl/O3bt3L+7t27ytnq6qp81q2EnZ6eynkjrvhzeHMCoQgnEIpwAqEIJxCKcAKhCCcQinACoWJ7zqOjIzl360lv3rypnLm1K8etF42MjMh5d3d35ayrq0s+6z6X7e1tOXdHSKq1Ltdjzs/Py/ny8rKcq7Uvt0rnjrZMXAlzeHMCoQgnEIpwAqEIJxCKcAKhCCcQinACoWpqj61WqzVsyU1dk1eK7ypVX+h6yMnJSTmfnp6W8/HxcTnv7++vnLl9TLe36PZcP3z4cOW560jVcaSllLK7uyvn6jhUt8eauI/5py4uLi79x86bEwhFOIFQhBMIRTiBUIQTCEU4gVCEEwgV23PWq6mp+v+d1tZW+WxbW5ucd3R0yHl7e/uVv776vkvxfZ8799adB6yed9cy1rtTeZO7ynrQcwI3DOEEQhFOIBThBEIRTiAU4QRCEU4g1F/bcwI3BT0ncMMQTiAU4QRCEU4gFOEEQhFOIBThBEIRTiAU4QRCEU4gFOEEQhFOIBThBEIRTiAU4QRCEU4gFOEEQhFOIBThBEIRTiAU4QRCEU4glDwaE0Dj8OYEQhFOIBThBEIRTiAU4QRCEU4g1D+nAptZI8Kz2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m32sDnj6Txzb"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJwgLwUnT23s"
      },
      "source": [
        "Our goal is to build a classifier on MNIST. A first simple example of classifier is **logistic regression**, a particular case of **discriminative model**. The model for (multiclass) logistic regression is \n",
        "$$ p (y | \\mathbf{x} ) = \\text{Cat} (y |\\text{Softmax}(\\mathbf{W}\\mathbf{x}+\\mathbf{b})),$$\n",
        "where the unknown parameters are $\\mathbf{W}$ and $\\mathbf{b}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-2YQtR9Uiqk"
      },
      "source": [
        "**Question 1.** What are the dimensions of $\\mathbf{W}$ and $\\mathbf{b}$? What is the total number of parameters in the model?\n",
        "\n",
        "$$W\\in\\mathbb{R}^{784\\times784}$$\n",
        "$$b\\in\\mathbb{R}^{784}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffD2B-BUYwnl",
        "outputId": "c72164f3-3737-4161-f6ed-98646b833580"
      },
      "source": [
        "train_images[0].shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1UhiLHDU4da"
      },
      "source": [
        "We will build our logistic regression model using [**keras**](https://keras.io/), a nice deep learning API. In particular, keras's [sequential model](https://keras.io/guides/sequential_model/) is simple way of building compositions of parametric functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpTTmZ36T2T9"
      },
      "source": [
        "logistic_regression = tfk.Sequential([\n",
        "  tfkl.InputLayer(input_shape=[28*28,]),\n",
        "  tfkl.Dense(10, kernel_initializer=initializers.RandomNormal(stddev=1)) # because we have 10 classes\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj4QfIp0vKff"
      },
      "source": [
        "Here, $\\texttt{logistic_regression}$ represents the function $ \\mathbf{x} \\mapsto \\mathbf{W}\\mathbf{x}+\\mathbf{b}$, that takes vectors as inputs, and returns probabilities for each class. We can try with the first MNIST image. The model is initialised by sampling each coefficient of $\\mathbf{W}$ from a standard Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY-1z5qbUuKc",
        "outputId": "5aeaccaa-3c97-4b99-a4cf-3f19338764f6"
      },
      "source": [
        "logistic_regression(train_images[0:1,])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[  4.957146  ,  -1.5937662 , -11.296676  ,   4.0661845 ,\n",
              "          5.3883862 ,   0.08968258,   4.046138  ,  19.116106  ,\n",
              "          5.9716907 ,   2.6989236 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijfw4WfpvsP_"
      },
      "source": [
        "Note that the output is a Tensorflow tensor. One can easily get a Numpy array instead this way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHqYNRStUuMz",
        "outputId": "da4209c4-9662-4a3b-fc30-989dc584c306"
      },
      "source": [
        "logistic_regression(train_images[0:1,]).numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  4.957146  ,  -1.5937662 , -11.296676  ,   4.0661845 ,\n",
              "          5.3883862 ,   0.08968258,   4.046138  ,  19.116106  ,\n",
              "          5.9716907 ,   2.6989236 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umvYlfGBv2TX"
      },
      "source": [
        "This $\\texttt{logistic_regression}$ conveniently can also handle **batches** of inputs. Here we look at the predictions of the 10 first digits of MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OC4ZgXVv1hc",
        "outputId": "e5316c66-fd3b-4edd-fcde-a6d33ab41860"
      },
      "source": [
        "tf.nn.softmax(logistic_regression(train_images[0:10,]).numpy())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
              "array([[9.19034518e-03, 1.22150436e-06, 9.13724829e-09, 5.04491389e-01,\n",
              "        2.69801006e-07, 4.56146151e-01, 1.15229050e-04, 2.98278928e-02,\n",
              "        1.22637051e-04, 1.04851228e-04],\n",
              "       [9.99578059e-01, 1.62885287e-12, 1.99091343e-09, 1.01623385e-07,\n",
              "        3.83498531e-07, 2.12623709e-04, 2.96950966e-05, 1.61425807e-04,\n",
              "        5.82766745e-07, 1.70990170e-05],\n",
              "       [3.04732035e-04, 5.60324587e-09, 4.89987144e-07, 5.01623617e-05,\n",
              "        1.20544545e-01, 7.27342242e-10, 1.46382081e-04, 5.48300516e-10,\n",
              "        8.78846943e-01, 1.06800573e-04],\n",
              "       [1.67324921e-11, 9.99699235e-01, 7.99294939e-05, 7.05517550e-06,\n",
              "        1.05706931e-06, 1.24190201e-05, 5.20269859e-05, 3.25387965e-08,\n",
              "        1.47963234e-04, 3.41209756e-07],\n",
              "       [1.57138818e-08, 2.59365237e-07, 5.38553369e-10, 1.94413960e-08,\n",
              "        1.40428519e-05, 1.14459084e-07, 2.46329179e-08, 2.55801915e-05,\n",
              "        3.96089597e-08, 9.99959946e-01],\n",
              "       [1.49020491e-06, 5.31013788e-10, 9.99975681e-01, 3.16874718e-07,\n",
              "        4.04807965e-09, 3.40479505e-06, 4.32874570e-10, 1.15053214e-12,\n",
              "        1.37905516e-07, 1.87876394e-05],\n",
              "       [3.57507179e-06, 6.97982013e-02, 2.70041637e-02, 4.37972695e-02,\n",
              "        6.24219712e-04, 2.05898713e-02, 1.79148372e-02, 7.52676206e-05,\n",
              "        8.20186496e-01, 6.18187823e-06],\n",
              "       [5.16545288e-06, 7.72615597e-15, 2.96587981e-08, 2.85645761e-03,\n",
              "        1.76565081e-07, 1.63702371e-05, 3.44349216e-09, 1.46254211e-13,\n",
              "        7.30219018e-03, 9.89819705e-01],\n",
              "       [4.99081989e-06, 9.64180470e-01, 2.28469526e-05, 2.47487304e-04,\n",
              "        9.64370702e-05, 3.39859724e-02, 1.40082731e-04, 1.19327579e-03,\n",
              "        7.28914310e-05, 5.55595871e-05],\n",
              "       [5.65428581e-06, 8.36193614e-10, 6.99776237e-08, 9.79849665e-06,\n",
              "        9.99662161e-01, 3.33392163e-05, 8.76712591e-07, 1.50293330e-04,\n",
              "        5.88240109e-05, 7.89091428e-05]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v65KRekywEtx"
      },
      "source": [
        "One can check that each row of these predictions sums to one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9dvwvD5UuPQ",
        "outputId": "c72fc044-6b91-43a0-e55e-a09409a74cdf"
      },
      "source": [
        "np.sum(tf.nn.softmax(logistic_regression(train_images[0:10,]), axis=1).numpy(),1)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99999976, 1.0000001 , 1.0000001 , 1.        , 0.9999999 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LEUC7LCz_wG"
      },
      "source": [
        "One can us Tensorflow Probability to create the distribution  $p (y | \\mathbf{x} )$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tGJ3oYdT2WE"
      },
      "source": [
        "p_ygivenx_logistic_regression = tfd.Categorical(logits = logistic_regression(train_images[0:10,]))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLCouzqwQBW",
        "outputId": "e9129196-fc3c-41f0-c82e-9319460e407c"
      },
      "source": [
        "p_ygivenx_logistic_regression.sample() # sampling the predicted labels"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([5, 0, 8, 1, 9, 2, 8, 9, 1, 4], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCkZytXzwQDl",
        "outputId": "d33f5de7-b688-4386-9124-4923bf50a4ec"
      },
      "source": [
        "p_ygivenx_logistic_regression.mode() # looking at the most probable labels"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([3, 0, 8, 1, 9, 2, 8, 9, 1, 4], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD_RnKqm1W1N"
      },
      "source": [
        "# Training the logistic regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3E0_KzB1dRE"
      },
      "source": [
        "To train the classifier, we define a function that performs a gradient descent step. First, we choose the flavour of SGD that we want (in this case, the [fairly famous Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgMTlL-2wQFf"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5wus2n2Tubq"
      },
      "source": [
        "@tf.function\n",
        "def train_step_logistic_regression(data, labels):\n",
        "  with tf.GradientTape() as tape: # the gradient tape saves all the step that needs to be saved fopr automatic differentiation\n",
        "    p_ygivenx_logistic_regression = tfd.Categorical(logits = logistic_regression(data)) # One could also use logits rather than probs and remove the softmax layer...\n",
        "    logp_ygivenx_logistic_regression = p_ygivenx_logistic_regression.log_prob(labels)\n",
        "    loss = -tf.reduce_mean(logp_ygivenx_logistic_regression)  # the loss is the average negative log likelihood\n",
        "  gradients = tape.gradient(loss, logistic_regression.trainable_variables)  # here, the gradient is automatically computed\n",
        "  optimizer.apply_gradients(zip(gradients, logistic_regression.trainable_variables))  # Adam iteration"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EmfozUiTueC"
      },
      "source": [
        "@tf.function\n",
        "def evaluate_logistic_regression(data, labels):\n",
        "  p_ygivenx_logistic_regression = tfd.Categorical(logits = logistic_regression(data))\n",
        "  logp_ygivenx_logistic_regression = p_ygivenx_logistic_regression.log_prob(labels)\n",
        "  log_likelihood = tf.reduce_mean(logp_ygivenx_logistic_regression)\n",
        "  y_pred = p_ygivenx_logistic_regression.mode()\n",
        "  acc = tf.reduce_mean(tf.cast(y_pred == labels,tf.float32))\n",
        "  return acc, log_likelihood"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sRf2jgK4W9s",
        "outputId": "3df078e8-71b7-487a-8d90-5d47a92ade99"
      },
      "source": [
        " evaluate_logistic_regression(train_images,y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=0.08895>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-13.199782>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfcpUtie4_MC"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images,y_train)).shuffle(60000).batch(32) # TF creates the batches for us"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_XF8G4kTugJ",
        "outputId": "278f5465-66c5-4521-99fd-177f187e6ff2"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "  for images, labels in train_dataset:\n",
        "    train_step_logistic_regression(images, labels) # Adam iteration\n",
        "  acc, log_likelihood = evaluate_logistic_regression(train_images,y_train)\n",
        "  acc_test, log_likelihood_test = evaluate_logistic_regression(test_images,y_test)\n",
        "  print('Epoch  %g' %epoch)\n",
        "  print('Train accuracy  %g' %acc.numpy())\n",
        "  print('Test accuracy  %g' %acc_test.numpy())\n",
        "  print('Train log-likelihood  %g' %log_likelihood.numpy())\n",
        "  print('Test log-likelihood  %g' %log_likelihood_test.numpy())\n",
        "  print('-----------')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1\n",
            "Train accuracy  0.145983\n",
            "Test accuracy  0.1504\n",
            "Train log-likelihood  -8.6573\n",
            "Test log-likelihood  -8.63199\n",
            "-----------\n",
            "Epoch  2\n",
            "Train accuracy  0.231533\n",
            "Test accuracy  0.2457\n",
            "Train log-likelihood  -6.39438\n",
            "Test log-likelihood  -6.34201\n",
            "-----------\n",
            "Epoch  3\n",
            "Train accuracy  0.317467\n",
            "Test accuracy  0.3308\n",
            "Train log-likelihood  -4.89728\n",
            "Test log-likelihood  -4.84088\n",
            "-----------\n",
            "Epoch  4\n",
            "Train accuracy  0.40465\n",
            "Test accuracy  0.4143\n",
            "Train log-likelihood  -3.81866\n",
            "Test log-likelihood  -3.76308\n",
            "-----------\n",
            "Epoch  5\n",
            "Train accuracy  0.486033\n",
            "Test accuracy  0.4965\n",
            "Train log-likelihood  -3.06041\n",
            "Test log-likelihood  -3.00296\n",
            "-----------\n",
            "Epoch  6\n",
            "Train accuracy  0.551067\n",
            "Test accuracy  0.5613\n",
            "Train log-likelihood  -2.54242\n",
            "Test log-likelihood  -2.48152\n",
            "-----------\n",
            "Epoch  7\n",
            "Train accuracy  0.60165\n",
            "Test accuracy  0.6123\n",
            "Train log-likelihood  -2.18408\n",
            "Test log-likelihood  -2.12193\n",
            "-----------\n",
            "Epoch  8\n",
            "Train accuracy  0.639967\n",
            "Test accuracy  0.6532\n",
            "Train log-likelihood  -1.92648\n",
            "Test log-likelihood  -1.86627\n",
            "-----------\n",
            "Epoch  9\n",
            "Train accuracy  0.669917\n",
            "Test accuracy  0.6835\n",
            "Train log-likelihood  -1.73459\n",
            "Test log-likelihood  -1.67706\n",
            "-----------\n",
            "Epoch  10\n",
            "Train accuracy  0.693333\n",
            "Test accuracy  0.7053\n",
            "Train log-likelihood  -1.58677\n",
            "Test log-likelihood  -1.5316\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLOwSKOic8D-",
        "outputId": "18698c71-5cce-4e85-b978-94e4b798c1a7"
      },
      "source": [
        "print(logistic_regression(train_images[0:1,]), y_train[0], \"\", sep=\"\\n\")\n",
        "evaluate_logistic_regression(train_images[0:1,:],y_train[0])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 6.5466747 -2.3791492 -7.2746267 10.552074  -3.8893034 10.451341\n",
            "   2.1676915  7.7239656  2.2299993  2.0733109]], shape=(1, 10), dtype=float32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-0.7849399>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxH6tMP2eMh8",
        "outputId": "c35daa53-811a-48b7-aa7e-b205c025bd30"
      },
      "source": [
        "evaluate_logistic_regression(train_images[0:1,:]+mean_0, y_train[0])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-6.9726176>)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZZZwYgz3BK"
      },
      "source": [
        "**Question 2.** Compare the results of your logistic regression classifier with the ones given by scikit-learn's logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Ju1xtK0Cr8"
      },
      "source": [
        "**Question 3.** Replace the logistic regression model by a deep classifier of your choice (e.g. a MLP or a CNN). Try to beat logistic regression!"
      ]
    }
  ]
}