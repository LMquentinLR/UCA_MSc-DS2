{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66886dfd",
   "metadata": {},
   "source": [
    "# Information Theory\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "## Class 2 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939e39e",
   "metadata": {},
   "source": [
    "<u>**Self-information of 1 event $A$**</u>\n",
    "\n",
    "\\begin{align}\n",
    "h(A)&=-log_2\\,P(A)\\text{ sh}\\\\\n",
    "\\end{align}\n",
    "\n",
    "The entropy of a source $S=\\{s_1, ..., s_n\\}$ such that:\n",
    "\n",
    "\\begin{align}\n",
    "P(S=s_i)&\\overset{\\Delta}{=}p_i\\\\\n",
    "H(S)&=-\\underset{i=1}{\\overset{n}{\\sum}}p_i.log\\,p_i=\\mathbb{E}\\{h(s)\\}\n",
    "\\end{align}\n",
    "\n",
    "<u>**Self-information of 2 events $S=\\{0, 1\\}$**</u>\n",
    "\n",
    "\\begin{align}\n",
    "S&=\\{0, 1\\}\\\\\n",
    "P(S=0)&=p=1-P(S=1)\\\\\n",
    "H(S) &= -plog_2\\,p-(1-p)log_2\\,(1-p)\\\\\n",
    "\\end{align}\n",
    "\n",
    "If $p=0$, we result in $H(S)=0$ shannon per state.\n",
    "\n",
    "<hr> \n",
    "\n",
    "<center><span style=\"color:red\">The maximum shannon per state is **1**.</span></center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66190226",
   "metadata": {},
   "source": [
    "### Maximum entropy of a source S\n",
    "\n",
    "> The maximum entropy of a source $S$ is $H_{max}(S)=log_2\\,n\\,\\text{sh/state}$ with $n$ the number of states within $S$.\n",
    "\n",
    "<u>e.g. n=2</u>\n",
    "\n",
    "\\begin{align}\n",
    "H_{max}&=log_2(2)\\text{ sh/state}\\\\\n",
    "&=1\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9805b62",
   "metadata": {},
   "source": [
    "### Gibb's Inequality\n",
    "\n",
    "Consider 2 discrete probabiltiy distributions with mass functions $(p_1, ..., p_n)$ and $(q_1, ..., q_n)$. We have:\n",
    "\n",
    "$$\\underset{i=1}{\\overset{n}{\\sum}}p_i.log\\frac{q_i}{p_i}\\le0$$\n",
    "\n",
    "Equality is achieved when $p_i = q_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9b597e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "X, Y, two random variables with:\n",
    "\n",
    "\\begin{align}\n",
    "P(X=x_i, Y=y_j)&\\forall\\,i,\\,j\\\\\n",
    "i&\\in\\{1, ..., n\\}\\\\\n",
    "j&\\in\\{1, ..., n\\}\n",
    "\\end{align}\n",
    "\n",
    "We can introduce the joint entropy of the two variables.\n",
    "\n",
    "$$\\Rightarrow H(X, Y) = H(Z) = -\\underset{i=1}{\\overset{n}{\\sum}}\\underset{j=1}{\\overset{m}{\\sum}}P(X=x_i, Y=y_j).\\,log\\,P(X=x_i, Y=y_j)\\text{ shannon/state of (X, Y) (or pair of states)}$$\n",
    "\n",
    "There are $n\\times m$ states.\n",
    "\n",
    "<u>Notes:</u> $H_{max}(X, y)=log_2(nm)$ is reached when all the pairs of states have the same probability\n",
    "\n",
    "<u>If X and Y are independent</u>\n",
    "\n",
    "$$H(X, Y) = H(X)+H(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c8dd0",
   "metadata": {},
   "source": [
    "### Conditional Entropy\n",
    "\n",
    "We set $H(X|Y=y_j)$ the quantity of information provided by $X$ knowing that $Y=y_j$ (fixed). Also, $H(X|Y=y_j)$ is the amount of information needed to describe the outcome of $X$ given that we know that $Y=y_j$.\n",
    "\n",
    "\\begin{align}\n",
    "H(X|Y=y_j)&=-\\underset{i=1}{\\overset{n}{\\sum}}P(X=x_i|Y=y_j)log_2(P(X=x_i|Y=y_j))\\,\\,\\text{Sh/state of X}\\\\\n",
    "\\end{align}\n",
    "\n",
    "The conditional entropy of $X$ given $Y$ is defined as:\n",
    "\n",
    "$$H(X|Y)\\overset{\\Delta}{=}\\underset{j=1}{\\overset{m}{\\sum}}P(Y=y_j)H(X|Y=y_j)$$\n",
    "\n",
    "<u>If X and Y are independent</u>\n",
    "\n",
    "$$H(X|Y) = H(X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b580ffb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
